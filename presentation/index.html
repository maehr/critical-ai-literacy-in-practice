<!DOCTYPE html>
<html lang="en-US"><head>
<link href="../android-chrome-512x512.png" rel="icon" type="image/png">
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-c8ad9e5dbd60b7b70b38521ab19b7da4.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.34">

  <meta name="dcterms.date" content="2025-09-09">
  <meta name="keywords" content="Critical AI Literacy, Digital Humanities, Large Language Models, Research Ethics">
  <title>critical-ai-literacy-in-practice – Critical AI Literacy in Practice</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-12873a65cf666e61daa4b3cf91a98e13.css">
  <link rel="stylesheet" href="styles.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
<meta property="og:title" content="Critical AI Literacy in Practice – critical-ai-literacy-in-practice">
<meta property="og:description" content="This presentation explores critical AI literacy in digital humanities practice, examining current projects and their approaches to responsible AI implementation. Through case studies from Swiss institutions, we demonstrate how scholars can engage critically with AI tools while maintaining scholarly rigor and ethical standards.">
<meta property="og:image" content="https://maehr.github.io/critical-ai-literacy-in-practice/presentation/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta property="og:site_name" content="critical-ai-literacy-in-practice">
<meta name="twitter:title" content="Critical AI Literacy in Practice – critical-ai-literacy-in-practice">
<meta name="twitter:description" content="This presentation explores critical AI literacy in digital humanities practice, examining current projects and their approaches to responsible AI implementation. Through case studies from Swiss institutions, we demonstrate how scholars can engage critically with AI tools while maintaining scholarly rigor and ethical standards.">
<meta name="twitter:image" content="https://maehr.github.io/critical-ai-literacy-in-practice/presentation/data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==">
<meta name="twitter:card" content="summary_large_image">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Critical AI Literacy in Practice</h1>
  <p class="subtitle">Lessons from Current DH Projects</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Moritz Mähr <a href="https://orcid.org/0000-0002-1367-1618" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a>
</div>
<div class="quarto-title-author-email">
<a href="mailto:moritz.maehr@gmail.com">moritz.maehr@gmail.com</a>
</div>
        <p class="quarto-title-affiliation">
            University of Basel
          </p>
        <p class="quarto-title-affiliation">
            University of Bern
          </p>
    </div>
</div>

  <p class="date">September 9, 2025</p>
</section>
<section>
<section id="ai-is-everywhere-also-in-science" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>AI is Everywhere, also in Science</h1>

</section>
<section id="ai-in-publications" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-02_at_13.55.11.png" data-background-size="stretch" data-background-repeat="no-repeat" data-background-position="center">
<h2>AI in Publications</h2>
<div class="footer">
<p><a href="https://www.tudelft.nl/en/2025/eemcs/scientific-study-exposes-publication-fraud-involving-widespread-use-of-ai" class="footer-link-box" data-preview-link="false">Article</a></p>
</div>
<aside class="notes">
<p>Scientific Study Exposes Publication Fraud Involving Widespread Use of AI News - 23 June 2025 - Communication EWI A new study reveals the systematic use of generative artificial intelligence (GenAI) for the creation and publication of deceptive scientific articles over several years in the Global International Journal of Innovative Research. The issue came to light in 2024 when a fully fabricated article was falsely attributed to the study’s author.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ai-in-manuscripts" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-02_at_13.50.41.png" data-background-size="stretch" data-background-repeat="no-repeat" data-background-position="center">
<h2>AI in Manuscripts</h2>
<div class="footer">
<p><a href="https://www.nature.com/articles/d41586-025-02172-y" class="footer-link-box" data-preview-link="false">Article</a></p>
</div>
<aside class="notes">
<p>NEWS 11 July 2025 Scientists hide messages in papers to game AI peer review Some studies containing instructions in white text or small font — visible only to machines — will be withdrawn from preprint servers.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ai-in-experiments" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-02_at_11.22.46.png" data-background-size="stretch" data-background-repeat="no-repeat" data-background-position="center">
<h2>AI in Experiments</h2>
<div class="footer">
<p><a href="https://www.swissinfo.ch/eng/swiss-ai/fake-news-ai-study-when-researchers-do-more-harm-than-good/89435725" class="footer-link-box" data-preview-link="false">Article</a></p>
</div>
<aside class="notes">
<p>A controversial fake news study, carried out by Swiss-based researchers on the social media platform Reddit, has highlighted the ethical responsibilities and challenges of conducting studies on society.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="ai-in-experiments-1" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-02_at_11.23.22.png" data-background-size="stretch" data-background-repeat="no-repeat" data-background-position="center">
<h2>AI in Experiments</h2>
<div class="footer">
<p><a href="https://www.swissinfo.ch/eng/swiss-ai/fake-news-ai-study-when-researchers-do-more-harm-than-good/89435725" class="footer-link-box" data-preview-link="false">Article</a></p>
</div>
<aside class="notes">
<p>A controversial fake news study, carried out by Swiss-based researchers on the social media platform Reddit, has highlighted the ethical responsibilities and challenges of conducting studies on society.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section></section>
<section>
<section id="what-can-we-do-about-it" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>What can we do about it?</h1>

</section>
<section id="we-can" class="slide level2">
<h2>We can</h2>
<ol type="1">
<li>Understand the technology and its history</li>
</ol>
</section></section>
<section>
<section id="a-short-history-of-ai" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>A short history of AI</h1>
<aside class="notes">
<ul>
<li><strong>1950 – Turing’s Imitation Game:</strong> Alan Turing reframes the question of machine intelligence as a <strong>dialogue test</strong>, asking if a computer’s replies can indistinguishably mimic human conversation<a href="file:///file-FU3K3wVEo8RSMojzUj1pqd#:~:text=,2">[7]</a>. This philosophical turn placed <strong>language and interpretation</strong> at AI’s core.</li>
<li><strong>1960s – Early NLP &amp; ELIZA:</strong> Joseph Weizenbaum’s <strong>ELIZA (1966)</strong> chatbot uses simple keyword rules yet gives an illusion of understanding – a startling lesson in how interaction design (and human psychology) shape perceptions of AI. Around the same time, linguists and computer scientists begin collaborating (e.g.&nbsp;machine translation as a cryptographic puzzle in 1949, the ALPAC report in 1966 emphasizing evaluation).</li>
<li><strong>1980s–2000s – From Rules to Statistics:</strong> The late 80s see a <em>“statistical turn”</em> in NLP (IBM’s <em>Candide</em> translation system). By 2002, standardized metrics like <strong>BLEU</strong> for machine translation become dominant[, reflecting a new empirical, benchmark-driven mindset. Data-driven techniques overshadow earlier logic-based approaches, but also raise concerns about what gets lost (context, nuance) when focusing on narrow metrics.</li>
<li><strong>2010s – The Deep Learning Era:</strong> In 2013, <strong>Word2Vec</strong> demonstrated Firthian linguistics in action: <em>“You shall know a word by the company it keeps.”</em> Words were embedded as vectors, operationalizing the idea that <strong>meaning comes from usage context</strong>. 2017’s <strong>Transformer architecture</strong> (Vaswani et al.) revolutionized NLP by enabling much larger context and parallel processing. This paved the way for <strong>BERT (2018)</strong> and the family of <strong>GPT models (2018–2023)</strong> – culminating in ChatGPT and GPT-4, which brought versatile, human-like language generation to the public. (The term “LLM” entered common use, though its roots trace back through decades of linguistics and AI research.)</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="theoretical-ai" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-02_at_11.12.20.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Theoretical AI</h2>
<h3 class="bg-white" id="imitation-game">1950: Imitation Game</h3>
<div class="footer">
<p><a href="https://www.jstor.org/stable/2251299" class="footer-link-box" data-preview-link="true">Paper</a></p>
</div>
</section>
<section id="theoretical-ai-1" class="slide level2">
<h2>Theoretical AI</h2>
<h3 class="bg-white" id="imitation-game-1">1950: Imitation Game</h3>
<blockquote>
<p>The new form of the problem can be described in terms of a game which we call the ‘imitation game’. It is played with three people, a man (A), a woman (B), and an interrogator (C) who may be of either sex. The interrogator stays in a room apart from the other two.<br>
(…)<br>
We now ask the question, ’What will happen when a machine takes the part of A in this game?</p>
</blockquote>
</section>
<section id="symbolic-ai" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_20.01.57.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Symbolic AI</h2>
<h3 class="bg-white" id="eliza">1966: ELIZA</h3>
<div class="footer">
<p><a href="https://youtu.be/Ngma1gbcLEw?t=39" class="footer-link-box" data-preview-link="false">BBC footage</a></p>
</div>
<aside class="notes">
<p>ELIZA is an early natural language processing computer program created from 1964 to 1966 at the MIT Artificial Intelligence Laboratory by Joseph Weizenbaum. Created to demonstrate the superficiality of communication between man and machine, Eliza simulated conversation by using a ‘pattern matching’ and substitution methodology that gave users an illusion of understanding on the part of the program, but had no built in framework for contextualising events. <a href="https://en.wikipedia.org/wiki/File:ELIZA_conversation.png" class="uri">https://en.wikipedia.org/wiki/File:ELIZA_conversation.png</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="rule-based-ai" class="slide level2 bg-white" data-background-image="./images/item_1695664644591.jpeg" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Rule-based AI</h2>
<h3 class="bg-white" id="until-late-1980s-expert-systems-machine-translation">Until late 1980s: Expert Systems &amp; Machine Translation</h3>
<div class="footer">
<p><a href="https://www.ibm.com/history/machine-aided-translation" class="footer-link-box" data-preview-link="true">The Selectric on display in the IBM pavilion at the 1964-65 World’s Fair in New York.</a></p>
</div>
<aside class="notes">
<p><a href="https://en.wikipedia.org/wiki/Machine_translation" class="uri">https://en.wikipedia.org/wiki/Machine_translation</a> <a href="https://en.wikipedia.org/wiki/Rule-based_machine_translation" class="uri">https://en.wikipedia.org/wiki/Rule-based_machine_translation</a> <a href="https://en.wikipedia.org/wiki/Expert_system" class="uri">https://en.wikipedia.org/wiki/Expert_system</a> <a href="https://www.ibm.com/history/machine-aided-translation" class="uri">https://www.ibm.com/history/machine-aided-translation</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="statistical-ai" class="slide level2 bg-white" data-background-video="./images/Topic_model_scheme.webm" data-background-size="contain" data-background-video-loop="true">
<h2>Statistical AI</h2>
<h3 class="bg-white" id="late-1990searly-2000s-topic-modeling-data-mining">Late 1990s/early 2000s: Topic Modeling &amp; Data Mining</h3>
<div class="footer">
<p><a href="https://en.wikipedia.org/wiki/Topic_model" class="footer-link-box" data-preview-link="true">Topic Modeling</a></p>
</div>
<aside class="notes">
<p>Statistical approaches to AI emerged in the late 1990s and early 2000s, focusing on extracting patterns from large datasets. Topic modeling, developed by David Blei and others, became particularly important for digital humanities - allowing researchers to discover hidden thematic structures in large text corpora. This period also saw the rise of data mining techniques and statistical machine translation systems like IBM’s statistical models. <a href="https://en.wikipedia.org/wiki/Topic_model" class="uri">https://en.wikipedia.org/wiki/Topic_model</a> <a href="https://en.wikipedia.org/wiki/Data_mining" class="uri">https://en.wikipedia.org/wiki/Data_mining</a> <a href="https://en.wikipedia.org/wiki/Statistical_machine_translation" class="uri">https://en.wikipedia.org/wiki/Statistical_machine_translation</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="neural-ai" class="slide level2" data-background-image="./images/Word_vector_illustration.jpg" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Neural AI</h2>
<h3 class="bg-white" id="s-deep-learning-large-language-models">2010s: Deep Learning &amp; Large Language Models</h3>
<div class="footer">
<p><a href="https://en.wikipedia.org/wiki/Word2vec" class="footer-link-box" data-preview-link="true">Word2Vec</a></p>
</div>
<aside class="notes">
<ul>
<li><strong>2013: Word2Vec</strong> - Distributed representations of words</li>
<li><strong>2014: Sequence-to-sequence models</strong> - Neural machine translation</li>
<li><strong>2017: Transformer architecture</strong> - “Attention is All You Need”</li>
<li><strong>2018: BERT</strong> - Bidirectional encoder representations</li>
<li><strong>2019: GPT-2</strong> - Generative pre-trained transformers</li>
<li><strong>Neural networks learn patterns</strong> from massive text corpora</li>
</ul>
<p>The 2010s marked the neural revolution in AI. Word2Vec showed that word meanings could be captured as mathematical vectors. The Transformer architecture (2017) became the foundation for modern LLMs by introducing the attention mechanism. BERT demonstrated the power of bidirectional context understanding, while the GPT series showed that large-scale generative models could produce human-like text. This decade established the foundations for today’s AI systems. <a href="https://en.wikipedia.org/wiki/Neural_machine_translation" class="uri">https://en.wikipedia.org/wiki/Neural_machine_translation</a> <a href="https://upload.wikimedia.org/wikipedia/commons/3/3f/Word_vector_illustration.jpg" class="uri">https://upload.wikimedia.org/wikipedia/commons/3/3f/Word_vector_illustration.jpg</a></p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="generative-ai" class="slide level2" data-background-image="./images/Screenshot_2025-09-08_at_09.48.10.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Generative AI</h2>
<h3 class="bg-white" id="today-generative-ai-foundation-models">Today: Generative AI &amp; Foundation Models</h3>
<aside class="notes">
<ul>
<li><strong>Foundation models</strong> trained on massive datasets (text, images, code)</li>
<li><strong>Few-shot learning</strong> - models adapt to new tasks with minimal examples</li>
<li><strong>Multimodal capabilities</strong> - text, images, audio, video generation</li>
<li><strong>Scale effects</strong> - larger models show emergent capabilities</li>
<li><strong>Transformer-based architectures</strong> process sequences of tokens</li>
<li><strong>Pre-training + fine-tuning</strong> paradigm for specialization Today’s generative AI systems are built on foundation models - large neural networks trained on diverse data. They work by learning statistical patterns in token sequences, whether text, image patches, or other data types. The key insight is that scale matters: larger models with more parameters and training data exhibit emergent capabilities not seen in smaller models. These systems don’t “understand” in a human sense, but rather excel at pattern matching and statistical prediction.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="known-problems-of-generative-ai" class="slide level2">
<h2>Known problems of Generative AI</h2>
<ul>
<li><strong>Bias</strong> in training data</li>
<li>Lack of <strong>explainability</strong></li>
<li>Lack of <strong>transparency</strong></li>
<li>Lack of <strong>accountability</strong></li>
<li>Lack of <strong>reproducibility</strong></li>
<li><strong>Environmental impact</strong></li>
<li><strong>Ethical</strong> issues</li>
<li><strong>Legal</strong> issues</li>
<li><strong>Social</strong> issues</li>
<li><strong>Epistemological</strong> issues</li>
<li>…</li>
</ul>
</section></section>
<section>
<section id="what-can-we-do-about-it-1" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>What can we do about it?</h1>

</section>
<section id="we-can-1" class="slide level2">
<h2>We can</h2>
<ol type="1">
<li>Understand the technology and its history</li>
<li>Understand the limitations and problems of AI</li>
</ol>
</section>
<section id="critical-ai-studies" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_20.05.54.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Critical AI Studies</h2>
<div class="footer">
<p><a href="https://dl.acm.org/doi/10.1145/3442188.3445922" class="footer-link-box" data-preview-link="true">Paper</a></p>
</div>
</section></section>
<section>
<section id="teaching-ai-literacy" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>Teaching AI Literacy</h1>

</section>
<section id="critical-ai-literacy" class="slide level2">
<h2>Critical AI Literacy</h2>
<ul>
<li><strong>Technical literacy</strong>: Understanding how AI systems work, their capabilities and limitations</li>
<li><strong>Epistemological awareness</strong>: Questioning what counts as knowledge and how AI shapes it</li>
<li><strong>Ethical evaluation</strong>: Considering consent, privacy, transparency, and accountability</li>
<li><strong>Social impact assessment</strong>: Examining power structures, equity, and broader implications</li>
<li><strong>Practical application</strong>: Developing workflows that maintain scholarly rigor</li>
<li><strong>Continuous learning</strong>: Staying informed as technology evolves rapidly</li>
</ul>
<aside class="notes">
<p>Critical AI literacy goes beyond technical skills to encompass a holistic understanding of AI’s role in knowledge production. It requires scholars to be technically informed while maintaining critical distance. This means understanding both the potential and pitfalls of AI tools, developing ethical frameworks for their use, and considering their broader social implications. For digital humanists, this translates to maintaining traditional scholarly values while engaging productively with new technologies.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="decoding-inequality-unibe" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_10.07.18.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Decoding Inequality (UniBe)</h2>
<div class="footer">
<p><a href="https://dhbern.github.io/decoding-inequality-2025/" class="footer-link-box" data-preview-link="true">Course Description</a></p>
</div>
</section>
<section id="chatgpt-and-beyond-uzh" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_10.07.12.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>ChatGPT and Beyond (UZH)</h2>
<div class="footer">
<p><a href="https://www.sts.uzh.ch/en/students/pastsemesters/coursesFS25/Future-Skills/ChatGPT-and-Beyond--Interdisciplinary-Approaches-to-AI-Literacy.html" class="footer-link-box" data-preview-link="false">Course Description</a></p>
</div>
</section></section>
<section>
<section id="what-can-we-do-about-it-2" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>What can we do about it?</h1>

</section>
<section id="we-can-2" class="slide level2">
<h2>We can</h2>
<ol type="1">
<li>Understand the technology and its history</li>
<li>Understand the limitations and problems of AI</li>
<li>Make better use of AI tools</li>
</ol>
</section></section>
<section>
<section id="dh-in-action-swiss-projects-using-llms-tools-platforms" class="title-slide slide level1 center" data-background-color="#40666e">
<h1>DH in Action: Swiss Projects Using LLMs (Tools &amp; Platforms)</h1>

</section>
<section id="re-experiencing-history-with-ai-uzh" class="slide level2 bg-white" data-background-video="./images/fotor-ai-20250829152328.mp4" data-background-size="contain" data-background-video-loop="true">
<h2>Re-Experiencing History with AI (UZH)</h2>
<div class="footer">
<p><a href="https://www.hist.uzh.ch/de/fachbereiche/altegeschichte/lehrstuehle/maier/AIncient-Studies-Lab/Projects/Re-Experiencing-History.html" class="footer-link-box" data-preview-link="true">Project</a></p>
</div>
<aside class="notes">
<p>The University of Zurich’s “AIncient Studies Lab” has developed Re-Experiencing History, an AI-driven interactive platform that lets users generate historically grounded visualizations of Classical antiquity—from Roman triumphal processions to everyday scenes in ancient Greece. The tool employs prompt-based interfaces and fine-tuned image and video generation models, including DALL-E 3 and a specialized version of Flux.dev, incorporating latest research to avoid anachronisms and enhance authenticity. It supports user-guided experimentation with different visual models and prompt adjustments, enabling applications in education, museum exhibitions, research, documentaries, and tourism. Users can co-create their own interpretations, fostering deeper engagement with historical contexts. The platform also embodies cross-disciplinary collaboration between ancient history, computational linguistics, classical philology, digital humanities, and visualisation sciences. It will be made accessible soon via a web app requiring an account.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="data-visualization-to-access-cultural-archives-supsi-eth-library" class="slide level2 bg-white" data-background-image="./images/mini-muse-prototype.webp" data-background-size="contain" data-background-video-loop="true">
<h2>Data visualization to access cultural archives (SUPSI &amp; ETH Library)</h2>
<div class="footer">
<p><a href="https://mini-muse.github.io/project/" class="footer-link-box" data-preview-link="true">Project</a></p>
</div>
<aside class="notes">
<p><strong>Mini-Muse</strong> is a 12-month pilot exploring NLP and data visualization for exploratory access to digitized historical publications (E-Periodica).</p>
<ul>
<li><strong>Goals</strong>: Identify user needs, build a prototype with NLP annotations and a visual GUI, test usability.</li>
<li><strong>Method</strong>: Four work packages—user research, NLP development (rule-based + LLM, graph database, API), prototype design, evaluation with ETH Library.</li>
<li><strong>Dissemination</strong>: Presentations in 2025 at ETH Zurich and Digital Heritage (Siena).</li>
<li><strong>Limits</strong>: Small corpus (25 German political articles), usability focus over scalability.</li>
<li><strong>Next steps</strong>: Expand corpus, refine visualization, ensure FAIR compliance.</li>
</ul>
<p>Do you want me to compress this further into a 3-bullet executive summary?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="generating-alt-text-for-historical-sources-and-objects-stadt.geschichte.basel-university-of-basel" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_09.57.37.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>Generating alt text for historical sources and objects (Stadt.Geschichte.Basel, University of Basel)</h2>
<div class="footer">
<p><a href="https://maehr.github.io/dublin-core-metadata-enhancer/" class="footer-link-box" data-preview-link="true">Project</a></p>
</div>
<aside class="notes">
<p>Open-source pipeline that enriches Dublin Core metadata by fetching images, analyzing them with GPT-5, and generating WCAG-compliant alt texts. Reproducible, FAIR-aligned, licensed for open research.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="llm-benchmarking-for-humanities-tasks-rise-unibas" class="slide level2 bg-white" data-background-image="./images/Screenshot_2025-09-08_at_10.00.50.png" data-background-size="contain" data-background-repeat="no-repeat" data-background-position="center">
<h2>LLM benchmarking for humanities tasks (RISE, UNIBAS)</h2>
<div class="footer">
<p><a href="https://maehr.github.io/dublin-core-metadata-enhancer/documentation/" class="footer-link-box" data-preview-link="true">Project</a></p>
</div>
<aside class="notes">
<p>Humanities Data Benchmark (RISE-UNIBAS) is an open benchmark suite to test large language and multimodal models on humanities-relevant visual tasks.</p>
<p><strong>Core elements</strong></p>
<ul>
<li>Curated datasets (e.g.&nbsp;Fraktur OCR, bibliographic data, metadata extraction, Zettelkatalog)</li>
<li>Task definitions, prompts, and ground-truth answers</li>
<li>Automated evaluation scripts</li>
<li>Public leaderboard with model results</li>
</ul>
<p><strong>Context</strong></p>
<ul>
<li>Released August 2025, v0.2.0, GPL-3.0 license</li>
<li>Developed at University of Basel (Hindermann, Marti, Serif, Burkhardt)</li>
<li>Data + code openly available (~7.5 GB)</li>
</ul>
<p><strong>Use</strong> For researchers comparing model performance on historical/visual humanities data.</p>
<p><strong>Limits</strong> Covers only selected visual tasks; evaluation depends on dataset quality and chosen metrics.</p>
<p>Would you like me to map how this benchmark compares to existing ones like HSSBench or MMLU?</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="bibliography" class="slide level2 smaller">
<h2>Bibliography</h2>
<ul>
<li>Bender, Emily M., Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell.&nbsp;«On the&nbsp;Dangers&nbsp;of&nbsp;Stochastic Parrots:&nbsp;Can Language Models Be Too Big? 🦜». In&nbsp;<em>Proceedings of the 2021&nbsp;ACM Conference&nbsp;on&nbsp;Fairness,&nbsp;Accountability, and&nbsp;Transparency</em>, 610–23.&nbsp;FAccT&nbsp;’21. New York, NY, USA: Association for Computing Machinery, 2021.&nbsp;<a href="https://doi.org/10.1145/3442188.3445922" class="uri">https://doi.org/10.1145/3442188.3445922</a>.</li>
<li>Long, Duri, and Brian Magerko.&nbsp;«What Is&nbsp;AI Literacy?&nbsp;Competencies&nbsp;and&nbsp;Design Considerations». In&nbsp;<em>Proceedings of the 2020&nbsp;CHI Conference&nbsp;on&nbsp;Human Factors&nbsp;in&nbsp;Computing Systems</em>, 1–16.&nbsp;CHI&nbsp;’20. New York, NY, USA: Association for Computing Machinery, 2020.&nbsp;<a href="https://doi.org/10.1145/3313831.3376727" class="uri">https://doi.org/10.1145/3313831.3376727</a>.</li>
<li>Loukissas, Yanni A.&nbsp;<em>All Data Are Local: Thinking Critically in a Data-Driven Society</em>. Cambridge, Massachusetts: The MIT Press, 2019.&nbsp;<a href="https://doi.org/10.7551/mitpress/11543.001.0001" class="uri">https://doi.org/10.7551/mitpress/11543.001.0001</a>.</li>
<li>Mueller, Milton L.&nbsp;«It’s Just Distributed Computing:&nbsp;Rethinking AI&nbsp;Governance».&nbsp;<em>Telecommunications Policy</em>, Februar 2025, 102917.&nbsp;<a href="https://doi.org/10.1016/j.telpol.2025.102917" class="uri">https://doi.org/10.1016/j.telpol.2025.102917</a>.</li>
<li>O’Neil, Cathy.&nbsp;<em>Weapons of&nbsp;Math Destruction:&nbsp;How Big Data Increases Inequality&nbsp;and&nbsp;Threatens Democracy</em>. First edition. New York: Crown Publishing Group, 2016.</li>
<li>Offert, Fabian, and Ranjodh Singh Dhaliwal.&nbsp;«The&nbsp;Method&nbsp;of&nbsp;Critical AI Studies,&nbsp;A Propaedeutic», 10. Dezember 2024.&nbsp;<a href="https://doi.org/10.48550/arXiv.2411.18833" class="uri">https://doi.org/10.48550/arXiv.2411.18833</a>.</li>
</ul>
<aside class="notes">
<p>ELIZA conversation screenshot</p>
<ul>
<li><strong>Caption:</strong> Screenshot of a terminal session with ELIZA, Joseph Weizenbaum’s 1966 chatbot, simulating a psychotherapy dialogue.</li>
<li><strong>Alt text:</strong> Text-based interface showing an early interaction with ELIZA, where the program responds to user statements with reflective questions.</li>
</ul>
<p>Woman typing at a computer terminal (historical photo)</p>
<ul>
<li><strong>Caption:</strong> Demonstration of early computer interaction, likely during a public exhibition in the 1960s.</li>
<li><strong>Alt text:</strong> Black-and-white photo of a woman using a computer terminal in a public setting, with onlookers watching behind her.</li>
</ul>
<p>Turing’s 1950 paper</p>
<ul>
<li><strong>Caption:</strong> Title page of Alan Turing’s 1950 article “Computing Machinery and Intelligence” in <em>Mind</em>.</li>
<li><strong>Alt text:</strong> Journal cover page showing “MIND: A Quarterly Review of Psychology and Philosophy” with Alan Turing’s article “Computing Machinery and Intelligence.”</li>
</ul>
<p>Swissinfo fake news study headline</p>
<ul>
<li><strong>Caption:</strong> Swissinfo.ch article headline about a Swiss fake news study testing ethical boundaries in research.</li>
<li><strong>Alt text:</strong> News website screenshot showing article title “How a fake news study tested ethical research boundaries” with an image of a person wearing a “Fake News” T-shirt.</li>
</ul>
<p>Swissinfo fake news study article body</p>
<ul>
<li><strong>Caption:</strong> Swissinfo.ch article describing how researchers covertly used AI to manipulate debates on Reddit.</li>
<li><strong>Alt text:</strong> Screenshot of Swissinfo.ch article detailing a study linked to the University of Zurich, which deployed AI bots under pseudonyms to spread misinformation on Reddit.</li>
</ul>
<p>Nature article on gaming AI peer review</p>
<ul>
<li><strong>Caption:</strong> Nature article reporting that scientists embedded hidden instructions in papers to trick AI-based peer review.</li>
<li><strong>Alt text:</strong> News article screenshot titled “Scientists hide messages in papers to game AI peer review,” describing manipulation of AI tools in academic publishing.</li>
</ul>
<p>TU Delft publication fraud study</p>
<ul>
<li><strong>Caption:</strong> TU Delft report exposing systematic use of generative AI in fraudulent scientific publications.</li>
<li><strong>Alt text:</strong> University news page featuring Professor Diomidis Spinellis and an article titled “Scientific Study Exposes Publication Fraud Involving Widespread Use of AI.”</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp("https:\/\/maehr\.github\.io\/critical-ai-literacy-in-practice\/");
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>